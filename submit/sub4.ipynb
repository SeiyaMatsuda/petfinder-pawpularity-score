{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087a7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "sys.path.append(\"../input/timmmaster/\")\n",
    "sys.path.append(\"../input/matsuda-utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e840ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from cuml.svm import SVR\n",
    "import time\n",
    "import pandas_profiling as pdp\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils.util import *\n",
    "from utils.losses import *\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import transformers as T\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import albumentations\n",
    "import tez\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32a4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    DATA_PATH = Path('../input/petfinder-pawpularity-score')\n",
    "    MODEL_NAME = 'swin_large_patch4_window12_384'\n",
    "    MODEL_PATH = Path(f'../input/pretrained_models/swin_large_patch4_window12_384_add_petcategory/')\n",
    "    batch_size = 32\n",
    "    image_size = 384\n",
    "    fold = 5\n",
    "    device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42e6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(CONFIG.DATA_PATH / 'test.csv')\n",
    "test_df['path'] = test_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'test'/x)+'.jpg')\n",
    "test_df['image_size'] = test_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "test_df['width'] = test_df['image_size'].apply(lambda x: x[0])\n",
    "test_df['height'] = test_df['image_size'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e526f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4dc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, df, dense_features, targets, augmentations):\n",
    "        self.image_paths = df['path'].tolist()\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        if self.targets is None:\n",
    "            self.targets = torch.ones(len(self.image_paths))\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        targets = self.targets[item]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        features = self.dense_features[item, :]\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bac9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularModel(nn.Module):\n",
    "    def __init__(self, pet_classify_model, model_name):\n",
    "        super().__init__()\n",
    "        self.pet_classify_model = pet_classify_model\n",
    "        self.pet_classify_model.requires_grad = False\n",
    "        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(177, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        p = self.pet_classify_model(F.adaptive_avg_pool2d(image, (224,224)))\n",
    "        p = torch.softmax(p, dim=1)\n",
    "        x1 = self.model(image)\n",
    "        x = self.dropout(x1)\n",
    "        x = torch.cat([x, features, p], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return torch.cat([x, x1, features, p], dim=1)\n",
    "    \n",
    "class pet_categor_extract_model(nn.Module):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, in_chans=3)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Linear(128\n",
    "                               , class_num)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf984f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, df):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    df_folds = df.reset_index(drop=True)\n",
    "    \n",
    "    dataset = PawpularDataset(\n",
    "        df_folds, \n",
    "        dense_features=df_folds[dense_features].values, targets=None,\n",
    "        augmentations=test_aug\n",
    "    )\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    embedding_feature = []\n",
    "    \n",
    "    for iter, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "        img, feature ,target = data['image'],  data['features'], data['targets']\n",
    "        img = img.to(CONFIG.device)\n",
    "        feature = feature.to(CONFIG.device)\n",
    "        target = target.to(CONFIG.device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            embedding = model(img, feature)\n",
    "        embedding_feature.append(embedding.data.cpu())\n",
    "    \n",
    "    embedding_feature = np.concatenate(embedding_feature)\n",
    "\n",
    "    return embedding_feature[:,:1].ravel().tolist(), embedding_feature[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8d0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "def main():\n",
    "    super_final_predictions = []\n",
    "    super_final_predictions2 = []\n",
    "    super_final_oof_predictions = []\n",
    "    super_final_oof_predictions2 = []\n",
    "    super_final_oof_true = []\n",
    "    for fold in range(CONFIG.fold):\n",
    "\n",
    "        # ====================================================\n",
    "        # Data Loader\n",
    "        # ====================================================\n",
    "        cl_model = pet_categor_extract_model(class_num=37)\n",
    "        cl_model.to(CONFIG.device)\n",
    "        model = PawpularModel(cl_model, model_name=CONFIG.MODEL_NAME)\n",
    "        model.to(CONFIG.device)\n",
    "\n",
    "        if torch.cuda.device_count()>1:\n",
    "            model=nn.DataParallel(model)\n",
    "            model.load_state_dict(torch.load(CONFIG.MODEL_PATH / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(fix_model_state_dict(torch.load(CONFIG.MODEL_PATH / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"]))\n",
    "            \n",
    "        test_folds = test_df.reset_index(drop=True)\n",
    "        preds_test, embed_test = extract_feature(model, test_folds)\n",
    "        print('Loading SVR...')\n",
    "        clf = pickle.load(open(CONFIG.MODEL_PATH / f\"SVR_fold_{fold}.pkl\", \"rb\"))\n",
    "        ##fit SVR to test data\n",
    "        test_pred_SVR = clf.predict(embed_test.astype('float32'))\n",
    "        test_pred_NN  =[sigmoid(x) * 100 for x in preds_test]\n",
    "        \n",
    "        super_final_predictions.append(test_pred_SVR)\n",
    "        super_final_predictions2.append(test_pred_NN)\n",
    "        \n",
    "    # submission\n",
    "    submission = test_df.copy()\n",
    "    \n",
    "    best_w = 0.5\n",
    "    super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n",
    "    super_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\n",
    "    submission[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\n",
    "    submission = submission[[\"Id\", \"Pawpularity\"]]\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467634bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d330bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75226164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

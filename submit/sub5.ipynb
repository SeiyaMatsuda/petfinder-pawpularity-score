{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b80285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on the post here: https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/275094\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# sys.path.append(\"../input/tez-lib/\")\n",
    "# sys.path.append(\"../input/timmmaster/\")\n",
    "# sys.path.append(\"../input/matsuda-utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27817687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import time\n",
    "import pandas_profiling as pdp\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils.util import *\n",
    "from utils.losses import *\n",
    "import torch.nn as nn\n",
    "import transformers as T\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tez.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import tez\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c238ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    DATA_PATH = Path('../input/petfinder-pawpularity-score')\n",
    "    MODEL_NAME = 'swin_large_patch4_window12_384'\n",
    "    MODEL_PATH = Path(f'../input/pretrained_models/swin_large_patch4_window12_384_add_petcategory/')\n",
    "    batch_size = 32\n",
    "    image_size = 384\n",
    "    fold = 5\n",
    "    device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d28879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from u2net_test import extract\n",
    "# extract(str(CONFIG.DATA_PATH) + '/train',str(CONFIG.DATA_PATH)+ '/train_U2NET')\n",
    "extract(str(CONFIG.DATA_PATH) +'/test', str(CONFIG.DATA_PATH) +  '/test_U2NET')\n",
    "# extract(str(CONFIG.NO_LABEL_DATA_PATH) + '/train_images',str(CONFIG.NO_LABEL_DATA_PATH)+ '/train_U2NET')\n",
    "# extract(str(CONFIG.NO_LABEL_DATA_PATH) +'/test_images', str(CONFIG.NO_LABEL_DATA_PATH) +  '/test_U2NET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9da0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(CONFIG.DATA_PATH / 'train.csv')\n",
    "train_df['path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train'/x)+'.jpg')\n",
    "train_df['mask_path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train_U2NET'/x)+'.jpg')\n",
    "train_df['image_size'] = train_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "train_df['width'] = train_df['image_size'].apply(lambda x: x[0])\n",
    "train_df['height'] = train_df['image_size'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9e29993",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34274910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, df, targets, augmentations):\n",
    "        self.image_paths = df['path'].tolist()\n",
    "        self.mask_paths = df['mask_path'].tolist()\n",
    "        self.targets = targets\n",
    "        if self.targets is None:\n",
    "            self.targets = torch.ones(len(self.image_paths))\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_paths[item])\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        h_max = 0\n",
    "        h_min = mask.shape[0]\n",
    "        w_max = 0\n",
    "        w_min = mask.shape[1]\n",
    "        idx = np.where(mask > 127.5)\n",
    "        try:\n",
    "            h_max = idx[0].min()\n",
    "            h_min = idx[0].max()\n",
    "            w_max = idx[1].min()\n",
    "            w_min = idx[1].max()\n",
    "        except:\n",
    "            pass\n",
    "        image = image[h_max:h_min, w_max:w_min,:]\n",
    "        mask = mask[h_max:h_min, w_max:w_min]\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        \n",
    "        targets = self.targets[item]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"mask\" : torch.tensor(mask, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f188a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularModel(nn.Module):\n",
    "    def __init__(self, pet_classify_model, model_name):\n",
    "        super().__init__()\n",
    "        self.pet_classify_model = pet_classify_model\n",
    "        self.pet_classify_model.requires_grad = False\n",
    "        self.model = timm.create_model(model_name, pretrained=CONFIG.pretrained, in_chans=3)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(128+37, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        p = self.pet_classify_model(F.adaptive_avg_pool2d(image, (224,224)))\n",
    "        p = torch.softmax(p, dim=1)\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, p], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return torch.sigmoid(x.squeeze(1))\n",
    "    \n",
    "class pet_categor_extract_model(nn.Module):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, in_chans=3)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Linear(128\n",
    "                               , class_num)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ef76c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    predictions = []\n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    test_dataset = PawpularDataset(\n",
    "        test_df, targets=None,\n",
    "        augmentations=test_aug\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    for fold in range(5):\n",
    "        LOGGER.info(f\"========== model: {CONFIG.MODEL_NAME} fold: {fold} inference ==========\")\n",
    "        cl_model = pet_categor_extract_model(class_num=37)\n",
    "        cl_model.to(CONFIG.device)\n",
    "        cl_model.load_state_dict(fix_model_state_dict(torch.load('../input/pretrained_models/efficientnet_b0_Oxford_classifier_size_224.pth')[\"model\"]))\n",
    "\n",
    "        model = PawpularModel(cl_model, model_name=CONFIG.MODEL_NAME)\n",
    "        model.to(CONFIG.device)\n",
    "        if torch.cuda.device_count()>1:\n",
    "            model=nn.DataParallel(model)\n",
    "            model.load_state_dict(torch.load(CONFIG.OUTPUT_DIR / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(fix_model_state_dict(torch.load(CONFIG.OUTPUT_DIR / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"]))\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            img, mask, target = data['image'], data['mask'], data['targets']\n",
    "            img = img.to(CONFIG.device)\n",
    "            target = target.to(CONFIG.device)\n",
    "            \n",
    "            img = (img * (mask>0.5).unsqueeze(1)).to(device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(img)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "        predictions.append(preds)\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "    return predictions * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35fb840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Inference\n",
    "    predictions = inference()\n",
    "    # submission\n",
    "    submission = test_df.copy()\n",
    "    submission[\"Pawpularity\"] = predictions\n",
    "    submission = submission[[\"Id\", \"Pawpularity\"]]\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fa2ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "  0%|                                                                                                      | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "  0%|                                                                                                      | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "  0%|                                                                                                      | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.55it/s]\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "  0%|                                                                                                      | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba030485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3763b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

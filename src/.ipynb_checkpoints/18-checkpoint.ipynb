{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd7a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/U-2-Net/')\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809526f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from u2net_test import extract\n",
    "# extract('../input/petfinder-pawpularity-score/train', '../input/petfinder-pawpularity-score/train_U2NET')\n",
    "# extract('../input/petfinder-pawpularity-score/test', '../input/petfinder-pawpularity-score/test_U2NET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3840bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import time\n",
    "import pandas_profiling as pdp\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils.util import *\n",
    "from utils.losses import *\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import transformers as T\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import ttach as tta\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import albumentations\n",
    "import tez\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf478c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    DATA_PATH = Path('../input/petfinder-pawpularity-score')\n",
    "    OUTPUT_DIR = Path('../output/31')\n",
    "    TEACHER_MODEL_PATH = Path('../output/21')\n",
    "    TEACHER_MODEL_NAME = 'swin_large_patch4_window12_384'\n",
    "    STUDENT_MODEL_NAME = 'swin_large_patch4_window7_224'\n",
    "    \n",
    "    batch_size = 16\n",
    "    image_size = 224\n",
    "    fold = 5\n",
    "    epoch = 20\n",
    "    lr = 1e-5\n",
    "    device='cuda'\n",
    "    training_step=True\n",
    "    pretrained=True\n",
    "    SEED=999\n",
    "    MIX_UP = True\n",
    "    MASK = False\n",
    "if not os.path.isdir(CONFIG.OUTPUT_DIR):\n",
    "    os.makedirs(CONFIG.OUTPUT_DIR)\n",
    "LOGGER = init_logger(OUTPUT_DIR=CONFIG.OUTPUT_DIR)\n",
    "fix_seed(CONFIG.SEED)\n",
    "pet_category = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair',\n",
    " 'Egyptian_Mau' ,'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue' ,'Siamese',\n",
    " 'Sphynx', 'american_bulldog' ,'american_pit_bull_terrier', 'basset_hound',\n",
    " 'beagle', 'boxer' ,'chihuahua', 'english_cocker_spaniel', 'english_setter',\n",
    " 'german_shorthaired' ,'great_pyrenees', 'havanese', 'japanese_chin',\n",
    " 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian',\n",
    " 'pug' ,'saint_bernard' ,'samoyed' ,'scottish_terrier', 'shiba_inu',\n",
    " 'staffordshire_bull_terrier' ,'wheaten_terrier' ,'yorkshire_terrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3593049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>image_size</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train_U2N...</td>\n",
       "      <td>(405, 720)</td>\n",
       "      <td>405</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train_U2N...</td>\n",
       "      <td>(1032, 774)</td>\n",
       "      <td>1032</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train_U2N...</td>\n",
       "      <td>(720, 960)</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train_U2N...</td>\n",
       "      <td>(405, 720)</td>\n",
       "      <td>405</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train_U2N...</td>\n",
       "      <td>(540, 960)</td>\n",
       "      <td>540</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "                                                path  \\\n",
       "0  ../input/petfinder-pawpularity-score/train/000...   \n",
       "1  ../input/petfinder-pawpularity-score/train/000...   \n",
       "2  ../input/petfinder-pawpularity-score/train/001...   \n",
       "3  ../input/petfinder-pawpularity-score/train/001...   \n",
       "4  ../input/petfinder-pawpularity-score/train/001...   \n",
       "\n",
       "                                           mask_path   image_size  width  \\\n",
       "0  ../input/petfinder-pawpularity-score/train_U2N...   (405, 720)    405   \n",
       "1  ../input/petfinder-pawpularity-score/train_U2N...  (1032, 774)   1032   \n",
       "2  ../input/petfinder-pawpularity-score/train_U2N...   (720, 960)    720   \n",
       "3  ../input/petfinder-pawpularity-score/train_U2N...   (405, 720)    405   \n",
       "4  ../input/petfinder-pawpularity-score/train_U2N...   (540, 960)    540   \n",
       "\n",
       "   height  \n",
       "0     720  \n",
       "1     774  \n",
       "2     960  \n",
       "3     720  \n",
       "4     960  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(CONFIG.DATA_PATH / 'train.csv')\n",
    "train_df['path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train'/x)+'.jpg')\n",
    "train_df['mask_path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train_U2NET'/x)+'.jpg')\n",
    "train_df['image_size'] = train_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "train_df['width'] = train_df['image_size'].apply(lambda x: x[0])\n",
    "train_df['height'] = train_df['image_size'].apply(lambda x: x[1])\n",
    "\n",
    "test_df = pd.read_csv(CONFIG.DATA_PATH / 'test.csv')\n",
    "test_df['path'] = test_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'test'/x)+'.jpg')\n",
    "test_df['image_size'] = test_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "test_df['width'] = test_df['image_size'].apply(lambda x: x[0])\n",
    "test_df['height'] = test_df['image_size'].apply(lambda x: x[1])\n",
    "\n",
    "if CONFIG.MASK:\n",
    "    train_df['mask_path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train_U2NET'/x)+'.jpg')\n",
    "    test_df['mask_path'] = test_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'test_U2NET'/x)+'.jpg')\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684510fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n",
    "train_df = get_train_data(train_df, train_df['Pawpularity'], n_splits = CONFIG.fold, regression=True, num_bins=num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = albumentations.Compose(\n",
    "    [\n",
    "    albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "    albumentations.HueSaturationValue(\n",
    "            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n",
    "        ),\n",
    "    albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n",
    "        ),\n",
    "    albumentations.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "        max_pixel_value=255.0,\n",
    "        p=1.0,)],p=1.0,\n",
    ")\n",
    "\n",
    "teacher_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(384,384, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ea73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, df, targets, augmentations, mask=True):\n",
    "        self.image_paths = df['path'].tolist()\n",
    "        self.mask = mask\n",
    "        if self.mask:\n",
    "            self.mask_paths = df['mask_path'].tolist()\n",
    "        self.targets = targets\n",
    "        if self.targets is None:\n",
    "            self.targets = torch.ones(len(self.image_paths))\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.mask:\n",
    "            mask = cv2.imread(self.mask_paths[item])\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            idx = np.where(mask > 127.5)\n",
    "            h_max = idx[0].min()\n",
    "            h_min = idx[0].max()\n",
    "            w_max = idx[1].min()\n",
    "            w_min = idx[1].max()\n",
    "        \n",
    "            image = image[h_max:h_min, w_max:w_min,:]\n",
    "            mask = mask[h_max:h_min, w_max:w_min]\n",
    "            image = image * np.expand_dims(mask > 127.5, 2)\n",
    "            \n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "        else:\n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "\n",
    "        targets = self.targets[item]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f011016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularModel(nn.Module):\n",
    "    def __init__(self, pet_classify_model, model_name):\n",
    "        super().__init__()\n",
    "        self.pet_classify_model = pet_classify_model\n",
    "        self.pet_classify_model.requires_grad = False\n",
    "        self.model = timm.create_model(model_name, pretrained=CONFIG.pretrained, in_chans=3)\n",
    "#         self.model.patch_embed.proj=nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4))\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(128+37, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        p = self.pet_classify_model(F.adaptive_avg_pool2d(image, (224,224)))\n",
    "        p = torch.softmax(p, dim=1)\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, p], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return torch.sigmoid(x.squeeze(1))\n",
    "    \n",
    "class pet_categor_extract_model(nn.Module):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=False, in_chans=3)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Linear(128\n",
    "                               , class_num)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c095407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, scheduler, batch_size, epoch, device):\n",
    "    start = end = time.time()\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    for iter, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        img ,target = data['image'], data['targets']\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "        if torch.rand(1)[0] < 0.5 and CONFIG.MIX_UP:\n",
    "            mix_images, target_a, target_b, lam = mixup(img, target, alpha=0.5)\n",
    "            y_preds = model(mix_images)\n",
    "            loss = criterion(y_preds, target_a) * lam + \\\n",
    "                (1 - lam) * criterion(y_preds, target_b)\n",
    "        else:\n",
    "            y_preds = model(img)\n",
    "            loss = criterion(y_preds, target)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    start = end = time.time()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for iter, data in enumerate(valid_loader):\n",
    "        img ,target = data['image'], data['targets']\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(img)\n",
    "\n",
    "        loss = criterion(y_preds, target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record score\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def give_label(train_loader, teacher_model, device='cuda'):\n",
    "    start = end = time.time()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    teacher_model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for iter, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        img = data['image']\n",
    "        img = img.to(device)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = teacher_model(img)\n",
    "\n",
    "        # record score\n",
    "        preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "    soft_target = np.concatenate(preds) * 100\n",
    "    return soft_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b62afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train, fold_):\n",
    "    LOGGER.info(f\"========== fold: {fold_} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    cl_model = pet_categor_extract_model(class_num=37)\n",
    "    cl_model.to(CONFIG.device)\n",
    "    \n",
    "    tc_model =  PawpularModel(cl_model, model_name=CONFIG.TEACHER_MODEL_NAME)\n",
    "    tc_model.to(CONFIG.device)\n",
    "    tc_model.load_state_dict(fix_model_state_dict(torch.load(CONFIG.TEACHER_MODEL_PATH / f\"{CONFIG.TEACHER_MODEL_NAME}_{fold_}_best.pth\")[\"model\"]))\n",
    "    \n",
    "    if torch.cuda.device_count()>1:\n",
    "        tc_model=nn.DataParallel(tc_model)\n",
    "    \n",
    "    st_model =  PawpularModel(cl_model, model_name=CONFIG.STUDENT_MODEL_NAME)\n",
    "    st_model.to(CONFIG.device)           \n",
    "    if torch.cuda.device_count()>1:\n",
    "        st_model=nn.DataParallel(st_model)\n",
    "    earlystopping= EarlyStopping(patience=3, path=CONFIG.OUTPUT_DIR / f\"{CONFIG.STUDENT_MODEL_NAME}_{fold_}_latest.pth\")\n",
    "    \n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    train_idx = train[train.fold!=fold_].index\n",
    "    val_idx = train[train.fold ==fold_].index\n",
    "    train_folds = train.loc[train_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    teacher_dataset = PawpularDataset(\n",
    "        train_folds, targets=None,\n",
    "        augmentations=teacher_aug, mask=CONFIG.MASK\n",
    "    )\n",
    "    \n",
    "    val_dataset = PawpularDataset(\n",
    "        valid_folds, targets=valid_folds['Pawpularity']/100,\n",
    "        augmentations=test_aug, mask=CONFIG.MASK\n",
    "    )\n",
    "    teacher_loader = DataLoader(\n",
    "        teacher_dataset,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    soft_target = give_label(teacher_loader, tc_model, CONFIG.device)\n",
    "    tc_model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    train_dataset = PawpularDataset(\n",
    "        train_folds, targets=soft_target/100,\n",
    "        augmentations=train_aug, mask=CONFIG.MASK\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.AdamW(st_model.parameters(), lr=CONFIG.lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, eta_min=1e-4)\n",
    "    criterion = nn.BCELoss()\n",
    "    metric = RMSE()\n",
    "    best_score = np.inf\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    \n",
    "    for epoch in range(CONFIG.epoch):\n",
    "        start_time = time.time()\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, st_model, criterion, optimizer, scheduler, CONFIG.batch_size, epoch, CONFIG.device)\n",
    "#        # eval\n",
    "        ttac_model = tta.ClassificationTTAWrapper(st_model, tta.aliases.hflip_transform())\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, ttac_model, criterion, CONFIG.device)\n",
    "        valid_labels = torch.tensor(valid_folds[\"Pawpularity\"].values).float()\n",
    "        score = metric(preds * 100, valid_labels)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  lr: {scheduler.get_lr()[0]:.8f} time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(\n",
    "                {\"model\": st_model.state_dict(), \"preds\": preds * 100}, CONFIG.OUTPUT_DIR / f\"{CONFIG.STUDENT_MODEL_NAME}_{fold_}_best.pth\")\n",
    "            \n",
    "        earlystopping(avg_val_loss, st_model) #callメソッド呼び出し\n",
    "        if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "            \n",
    "    check_point = torch.load(CONFIG.OUTPUT_DIR / f\"{CONFIG.STUDENT_MODEL_NAME}_{fold_}_best.pth\")\n",
    "\n",
    "    valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f148dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    metric = RMSE()\n",
    "    preds = result_df[\"Pawpularity\"].values\n",
    "    labels = result_df[\"preds\"].values\n",
    "    score = metric(preds, labels)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c3fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    predictions = []\n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    test_dataset = PawpularDataset(\n",
    "        test_df, targets=None,\n",
    "        augmentations=test_aug, mask=CONFIG.MASK\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    for fold in range(5):\n",
    "        LOGGER.info(f\"========== model: {CONFIG.STUDENT_MODEL_NAME} fold: {fold} inference ==========\")\n",
    "        cl_model = pet_categor_extract_model(class_num=37)\n",
    "        cl_model.to(CONFIG.device)\n",
    "#         cl_model.load_state_dict(fix_model_state_dict(torch.load('../input/pretrained_models/efficientnet_b0_Oxford_classifier_size_224.pth')[\"model\"]))\n",
    "\n",
    "        model = PawpularModel(cl_model, model_name=CONFIG.STUDENT_MODEL_NAME)\n",
    "        model.to(CONFIG.device)\n",
    "        if torch.cuda.device_count()>1:\n",
    "            model=nn.DataParallel(model)\n",
    "            model.load_state_dict(torch.load(CONFIG.OUTPUT_DIR / f\"{CONFIG.STUDENT_MODEL_NAME}_{fold}_best.pth\")[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(fix_model_state_dict(torch.load(CONFIG.OUTPUT_DIR / f\"{CONFIG.STUDENT_MODEL_NAME}_{fold}_best.pth\")[\"model\"]))\n",
    "        model.eval()\n",
    "        ttac_model = tta.ClassificationTTAWrapper(model, tta.aliases.hflip_transform())\n",
    "        preds = []\n",
    "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            img,target = data['image'], data['targets']\n",
    "            img = img.to(CONFIG.device)\n",
    "            target = target.to(CONFIG.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = ttac_model(img)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "        predictions.append(preds)\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "    return predictions * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046331e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training\n",
    "    oof_df = pd.DataFrame()\n",
    "    if CONFIG.training_step:\n",
    "        for fold in range(CONFIG.fold):\n",
    "            _oof_df = train_loop(train_df, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "        # Save OOF result\n",
    "        oof_df.to_csv(CONFIG.OUTPUT_DIR / \"oof_df.csv\", index=False)\n",
    "    else:\n",
    "        oof_df = pd.read_csv(CONFIG.OUTPUT_DIR / \"oof_df.csv\")\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    # Inference\n",
    "    predictions = inference()\n",
    "    # submission\n",
    "    submission = test_df.copy()\n",
    "    submission[\"Pawpularity\"] = predictions\n",
    "    submission = submission[[\"Id\", \"Pawpularity\"]]\n",
    "    submission.to_csv(CONFIG.OUTPUT_DIR / \"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8c8949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "100%|████████████████████████████████████| 496/496 [02:29<00:00,  3.32it/s]\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.50it/s]\n",
      "Epoch 1 - avg_train_loss: 0.6467  avg_val_loss: 0.6424  lr: 0.00001055 time: 229s\n",
      "Epoch 1 - Score: 17.82813262939453\n",
      "Epoch 1 - Save Best Score: 17.8281 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 2 - avg_train_loss: 0.6422  avg_val_loss: 0.6414  lr: 0.00001220 time: 229s\n",
      "Epoch 2 - Score: 17.70417594909668\n",
      "Epoch 2 - Save Best Score: 17.7042 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 3 - avg_train_loss: 0.6414  avg_val_loss: 0.6415  lr: 0.00001490 time: 230s\n",
      "Epoch 3 - Score: 17.711658477783203\n",
      "100%|████████████████████████████████████| 495/495 [03:22<00:00,  2.45it/s]\n",
      "Epoch 4 - avg_train_loss: 0.6410  avg_val_loss: 0.6410  lr: 0.00001859 time: 233s\n",
      "Epoch 4 - Score: 17.65089988708496\n",
      "Epoch 4 - Save Best Score: 17.6509 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.49it/s]\n",
      "Epoch 5 - avg_train_loss: 0.6402  avg_val_loss: 0.6406  lr: 0.00002318 time: 230s\n",
      "Epoch 5 - Score: 17.59868621826172\n",
      "Epoch 5 - Save Best Score: 17.5987 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.48it/s]\n",
      "Epoch 6 - avg_train_loss: 0.6402  avg_val_loss: 0.6408  lr: 0.00002855 time: 231s\n",
      "Epoch 6 - Score: 17.61404800415039\n",
      "100%|████████████████████████████████████| 495/495 [03:17<00:00,  2.51it/s]\n",
      "Epoch 7 - avg_train_loss: 0.6398  avg_val_loss: 0.6403  lr: 0.00003457 time: 228s\n",
      "Epoch 7 - Score: 17.57532501220703\n",
      "Epoch 7 - Save Best Score: 17.5753 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.48it/s]\n",
      "Epoch 8 - avg_train_loss: 0.6408  avg_val_loss: 0.6400  lr: 0.00004109 time: 230s\n",
      "Epoch 8 - Score: 17.525976181030273\n",
      "Epoch 8 - Save Best Score: 17.5260 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:21<00:00,  2.45it/s]\n",
      "Epoch 9 - avg_train_loss: 0.6406  avg_val_loss: 0.6405  lr: 0.00004796 time: 233s\n",
      "Epoch 9 - Score: 17.57965850830078\n",
      "100%|████████████████████████████████████| 495/495 [03:23<00:00,  2.44it/s]\n",
      "Epoch 10 - avg_train_loss: 0.6407  avg_val_loss: 0.6403  lr: 0.00005500 time: 234s\n",
      "Epoch 10 - Score: 17.57444190979004\n",
      "100%|████████████████████████████████████| 495/495 [03:21<00:00,  2.46it/s]\n",
      "Epoch 11 - avg_train_loss: 0.6410  avg_val_loss: 0.6409  lr: 0.00006204 time: 232s\n",
      "Epoch 11 - Score: 17.643213272094727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 17.52598\n",
      "========== fold: 1 training ==========\n",
      "100%|████████████████████████████████████| 496/496 [02:31<00:00,  3.27it/s]\n",
      "100%|████████████████████████████████████| 495/495 [03:22<00:00,  2.44it/s]\n",
      "Epoch 1 - avg_train_loss: 0.6407  avg_val_loss: 0.6424  lr: 0.00001055 time: 234s\n",
      "Epoch 1 - Score: 17.856138229370117\n",
      "Epoch 1 - Save Best Score: 17.8561 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 2 - avg_train_loss: 0.6358  avg_val_loss: 0.6425  lr: 0.00001220 time: 237s\n",
      "Epoch 2 - Score: 17.869197845458984\n",
      "100%|████████████████████████████████████| 495/495 [03:21<00:00,  2.46it/s]\n",
      "Epoch 3 - avg_train_loss: 0.6346  avg_val_loss: 0.6420  lr: 0.00001490 time: 232s\n",
      "Epoch 3 - Score: 17.812227249145508\n",
      "Epoch 3 - Save Best Score: 17.8122 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.48it/s]\n",
      "Epoch 4 - avg_train_loss: 0.6346  avg_val_loss: 0.6441  lr: 0.00001859 time: 230s\n",
      "Epoch 4 - Score: 18.05044937133789\n",
      "100%|████████████████████████████████████| 495/495 [03:21<00:00,  2.45it/s]\n",
      "Epoch 5 - avg_train_loss: 0.6344  avg_val_loss: 0.6428  lr: 0.00002318 time: 234s\n",
      "Epoch 5 - Score: 17.911022186279297\n",
      "100%|████████████████████████████████████| 495/495 [03:21<00:00,  2.46it/s]\n",
      "Epoch 6 - avg_train_loss: 0.6341  avg_val_loss: 0.6417  lr: 0.00002855 time: 232s\n",
      "Epoch 6 - Score: 17.785879135131836\n",
      "Epoch 6 - Save Best Score: 17.7859 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 7 - avg_train_loss: 0.6341  avg_val_loss: 0.6414  lr: 0.00003457 time: 229s\n",
      "Epoch 7 - Score: 17.73676872253418\n",
      "Epoch 7 - Save Best Score: 17.7368 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.50it/s]\n",
      "Epoch 8 - avg_train_loss: 0.6336  avg_val_loss: 0.6430  lr: 0.00004109 time: 229s\n",
      "Epoch 8 - Score: 17.94805145263672\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.49it/s]\n",
      "Epoch 9 - avg_train_loss: 0.6347  avg_val_loss: 0.6434  lr: 0.00004796 time: 230s\n",
      "Epoch 9 - Score: 17.995763778686523\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 10 - avg_train_loss: 0.6341  avg_val_loss: 0.6415  lr: 0.00005500 time: 230s\n",
      "Epoch 10 - Score: 17.766550064086914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 17.73677\n",
      "========== fold: 2 training ==========\n",
      "100%|████████████████████████████████████| 496/496 [02:29<00:00,  3.33it/s]\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.50it/s]\n",
      "Epoch 1 - avg_train_loss: 0.6435  avg_val_loss: 0.6426  lr: 0.00001055 time: 229s\n",
      "Epoch 1 - Score: 17.880855560302734\n",
      "Epoch 1 - Save Best Score: 17.8809 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 2 - avg_train_loss: 0.6362  avg_val_loss: 0.6414  lr: 0.00001220 time: 229s\n",
      "Epoch 2 - Score: 17.714710235595703\n",
      "Epoch 2 - Save Best Score: 17.7147 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.50it/s]\n",
      "Epoch 3 - avg_train_loss: 0.6343  avg_val_loss: 0.6428  lr: 0.00001490 time: 229s\n",
      "Epoch 3 - Score: 17.892141342163086\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 4 - avg_train_loss: 0.6332  avg_val_loss: 0.6428  lr: 0.00001859 time: 230s\n",
      "Epoch 4 - Score: 17.889009475708008\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 5 - avg_train_loss: 0.6325  avg_val_loss: 0.6420  lr: 0.00002318 time: 229s\n",
      "Epoch 5 - Score: 17.80059051513672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 17.71471\n",
      "========== fold: 3 training ==========\n",
      "100%|████████████████████████████████████| 496/496 [02:28<00:00,  3.33it/s]\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.49it/s]\n",
      "Epoch 1 - avg_train_loss: 0.6366  avg_val_loss: 0.6466  lr: 0.00001055 time: 230s\n",
      "Epoch 1 - Score: 18.402666091918945\n",
      "Epoch 1 - Save Best Score: 18.4027 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:19<00:00,  2.49it/s]\n",
      "Epoch 2 - avg_train_loss: 0.6301  avg_val_loss: 0.6445  lr: 0.00001220 time: 230s\n",
      "Epoch 2 - Score: 18.132505416870117\n",
      "Epoch 2 - Save Best Score: 18.1325 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 3 - avg_train_loss: 0.6286  avg_val_loss: 0.6469  lr: 0.00001490 time: 230s\n",
      "Epoch 3 - Score: 18.403762817382812\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 4 - avg_train_loss: 0.6282  avg_val_loss: 0.6456  lr: 0.00001859 time: 230s\n",
      "Epoch 4 - Score: 18.275192260742188\n",
      "100%|████████████████████████████████████| 495/495 [03:18<00:00,  2.49it/s]\n",
      "Epoch 5 - avg_train_loss: 0.6276  avg_val_loss: 0.6419  lr: 0.00002318 time: 230s\n",
      "Epoch 5 - Score: 17.82610321044922\n",
      "Epoch 5 - Save Best Score: 17.8261 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:20<00:00,  2.47it/s]\n",
      "Epoch 6 - avg_train_loss: 0.6277  avg_val_loss: 0.6417  lr: 0.00002855 time: 232s\n",
      "Epoch 6 - Score: 17.814590454101562\n",
      "Epoch 6 - Save Best Score: 17.8146 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:20<00:00,  2.46it/s]\n",
      "Epoch 7 - avg_train_loss: 0.6277  avg_val_loss: 0.6412  lr: 0.00003457 time: 233s\n",
      "Epoch 7 - Score: 17.752859115600586\n",
      "Epoch 7 - Save Best Score: 17.7529 Model\n",
      "100%|████████████████████████████████████| 495/495 [03:27<00:00,  2.39it/s]\n",
      "Epoch 8 - avg_train_loss: 0.6283  avg_val_loss: 0.6429  lr: 0.00004109 time: 239s\n",
      "Epoch 8 - Score: 17.95598793029785\n",
      "100%|████████████████████████████████████| 495/495 [03:26<00:00,  2.39it/s]\n",
      "Epoch 9 - avg_train_loss: 0.6279  avg_val_loss: 0.6426  lr: 0.00004796 time: 239s\n",
      "Epoch 9 - Score: 17.92606544494629\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 10 - avg_train_loss: 0.6282  avg_val_loss: 0.6429  lr: 0.00005500 time: 238s\n",
      "Epoch 10 - Score: 17.95949363708496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 17.75286\n",
      "========== fold: 4 training ==========\n",
      "100%|█████████████████████████████████████████████████████████████████| 496/496 [02:34<00:00,  3.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:24<00:00,  2.41it/s]\n",
      "Epoch 1 - avg_train_loss: 0.6446  avg_val_loss: 0.6413  lr: 0.00001055 time: 237s\n",
      "Epoch 1 - Score: 17.780473709106445\n",
      "Epoch 1 - Save Best Score: 17.7805 Model\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:24<00:00,  2.42it/s]\n",
      "Epoch 2 - avg_train_loss: 0.6374  avg_val_loss: 0.6400  lr: 0.00001220 time: 237s\n",
      "Epoch 2 - Score: 17.60757827758789\n",
      "Epoch 2 - Save Best Score: 17.6076 Model\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 3 - avg_train_loss: 0.6358  avg_val_loss: 0.6399  lr: 0.00001490 time: 237s\n",
      "Epoch 3 - Score: 17.592361450195312\n",
      "Epoch 3 - Save Best Score: 17.5924 Model\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 4 - avg_train_loss: 0.6353  avg_val_loss: 0.6400  lr: 0.00001859 time: 237s\n",
      "Epoch 4 - Score: 17.60612678527832\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 5 - avg_train_loss: 0.6351  avg_val_loss: 0.6394  lr: 0.00002318 time: 237s\n",
      "Epoch 5 - Score: 17.52954864501953\n",
      "Epoch 5 - Save Best Score: 17.5295 Model\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 6 - avg_train_loss: 0.6343  avg_val_loss: 0.6396  lr: 0.00002855 time: 237s\n",
      "Epoch 6 - Score: 17.565319061279297\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:24<00:00,  2.42it/s]\n",
      "Epoch 7 - avg_train_loss: 0.6343  avg_val_loss: 0.6391  lr: 0.00003457 time: 237s\n",
      "Epoch 7 - Score: 17.48249053955078\n",
      "Epoch 7 - Save Best Score: 17.4825 Model\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:24<00:00,  2.42it/s]\n",
      "Epoch 8 - avg_train_loss: 0.6344  avg_val_loss: 0.6398  lr: 0.00004109 time: 237s\n",
      "Epoch 8 - Score: 17.57624053955078\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 9 - avg_train_loss: 0.6345  avg_val_loss: 0.6397  lr: 0.00004796 time: 238s\n",
      "Epoch 9 - Score: 17.566579818725586\n",
      "100%|█████████████████████████████████████████████████████████████████| 495/495 [03:25<00:00,  2.41it/s]\n",
      "Epoch 10 - avg_train_loss: 0.6342  avg_val_loss: 0.6404  lr: 0.00005500 time: 238s\n",
      "Epoch 10 - Score: 17.674230575561523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "Score: 17.48249\n",
      "========== CV ==========\n",
      "Score: 17.64293\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'CONFIG' has no attribute 'MODEL_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_315406/3832242952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_315406/2732515496.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_315406/1774993813.py\u001b[0m in \u001b[0;36minference\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== model: {CONFIG.MODEL_NAME} fold: {fold} inference ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mcl_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpet_categor_extract_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcl_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'CONFIG' has no attribute 'MODEL_NAME'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2156c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed07f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655e7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e742986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

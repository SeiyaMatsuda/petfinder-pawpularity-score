{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca9740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a12639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from cuml.svm import SVR\n",
    "import time\n",
    "import pandas_profiling as pdp\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils.util import *\n",
    "from utils.losses import *\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import transformers as T\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from utils.util import EarlyStopping\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import albumentations\n",
    "import tez\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2deda64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    DATA_PATH = Path('../input/petfinder-pawpularity-score')\n",
    "    OUTPUT_DIR = Path('../output/12')\n",
    "    MODEL_PATH = Path(f'../input/pretrained_models/swin_large_patch4_window12_384_add_petcategory')\n",
    "    MODEL_NAME = 'swin_large_patch4_window12_384'\n",
    "    batch_size = 10\n",
    "    fold=5\n",
    "    training_step=True\n",
    "    image_size = 384\n",
    "    device='cuda'\n",
    "    SEED=42\n",
    "if not os.path.isdir(CONFIG.OUTPUT_DIR):\n",
    "    os.makedirs(CONFIG.OUTPUT_DIR)\n",
    "LOGGER = init_logger(OUTPUT_DIR=CONFIG.OUTPUT_DIR)\n",
    "fix_seed(CONFIG.SEED)\n",
    "pet_category = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair',\n",
    " 'Egyptian_Mau' ,'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue' ,'Siamese',\n",
    " 'Sphynx', 'american_bulldog' ,'american_pit_bull_terrier', 'basset_hound',\n",
    " 'beagle', 'boxer' ,'chihuahua', 'english_cocker_spaniel', 'english_setter',\n",
    " 'german_shorthaired' ,'great_pyrenees', 'havanese', 'japanese_chin',\n",
    " 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian',\n",
    " 'pug' ,'saint_bernard' ,'samoyed' ,'scottish_terrier', 'shiba_inu',\n",
    " 'staffordshire_bull_terrier' ,'wheaten_terrier' ,'yorkshire_terrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c305b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(CONFIG.DATA_PATH / 'train.csv')\n",
    "train_df['path'] = train_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'train'/x)+'.jpg')\n",
    "train_df['image_size'] = train_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "train_df['width'] = train_df['image_size'].apply(lambda x: x[0])\n",
    "train_df['height'] = train_df['image_size'].apply(lambda x: x[1])\n",
    "\n",
    "test_df = pd.read_csv(CONFIG.DATA_PATH / 'test.csv')\n",
    "test_df['path'] = test_df['Id'].map(lambda x:str(CONFIG.DATA_PATH/'test'/x)+'.jpg')\n",
    "test_df['image_size'] = test_df['path'].apply(lambda image_id : Image.open(image_id).size)\n",
    "test_df['width'] = test_df['image_size'].apply(lambda x: x[0])\n",
    "test_df['height'] = test_df['image_size'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad7ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_train_data(train_df, train_df['Pawpularity'], n_splits = CONFIG.fold, regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb640a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = albumentations.Compose(\n",
    "    [\n",
    "    albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "#     albumentations.VerticalFlip(p=0.5),\n",
    "#     albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.HueSaturationValue(\n",
    "            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n",
    "        ),\n",
    "    albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n",
    "        ),\n",
    "    albumentations.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "        max_pixel_value=255.0,\n",
    "        p=1.0,)],p=1.0,\n",
    ")\n",
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "# train_aug = albumentations.Compose(\n",
    "#     [albumentations.Resize(CONFIG.image_size, CONFIG.image_size, p=1),\n",
    "#     albumentations.VerticalFlip(p=0.5),\n",
    "#     albumentations.HorizontalFlip(p=0.5)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c430811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, df, dense_features, targets, augmentations):\n",
    "        self.image_paths = df['path'].tolist()\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        if self.targets is None:\n",
    "            self.targets = torch.ones(len(self.image_paths))\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        targets = self.targets[item]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        features = self.dense_features[item, :]\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2660f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularModel(nn.Module):\n",
    "    def __init__(self, pet_classify_model, model_name):\n",
    "        super().__init__()\n",
    "        self.pet_classify_model = pet_classify_model\n",
    "        self.pet_classify_model.requires_grad = False\n",
    "        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(177, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        p = self.pet_classify_model(F.adaptive_avg_pool2d(image, (224,224)))\n",
    "        p = torch.softmax(p, dim=1)\n",
    "        x1 = self.model(image)\n",
    "        x = self.dropout(x1)\n",
    "        x = torch.cat([x, features, p], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return torch.cat([x, x1, features, p], dim=1)\n",
    "    \n",
    "class pet_categor_extract_model(nn.Module):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, in_chans=3)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Linear(128\n",
    "                               , class_num)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d058a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, df):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    df_folds = df.reset_index(drop=True)\n",
    "    \n",
    "    dataset = PawpularDataset(\n",
    "        df_folds, \n",
    "        dense_features=df_folds[dense_features].values, targets=None,\n",
    "        augmentations=test_aug\n",
    "    )\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=CONFIG.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    embedding_feature = []\n",
    "    \n",
    "    for iter, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "        img, feature ,target = data['image'],  data['features'], data['targets']\n",
    "        img = img.to(CONFIG.device)\n",
    "        feature = feature.to(CONFIG.device)\n",
    "        target = target.to(CONFIG.device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            embedding = model(img, feature)\n",
    "        embedding_feature.append(embedding.data.cpu())\n",
    "    \n",
    "    embedding_feature = np.concatenate(embedding_feature)\n",
    "\n",
    "    return embedding_feature[:,:1].ravel().tolist(), embedding_feature[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e5c1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "def main():\n",
    "    super_final_predictions = []\n",
    "    super_final_predictions2 = []\n",
    "    super_final_oof_predictions = []\n",
    "    super_final_oof_predictions2 = []\n",
    "    super_final_oof_true = []\n",
    "    for fold in range(CONFIG.fold):\n",
    "        LOGGER.info(f\"========== fold: {fold} extract ==========\")\n",
    "\n",
    "        # ====================================================\n",
    "        # Data Loader\n",
    "        # ====================================================\n",
    "        cl_model = pet_categor_extract_model(class_num=37)\n",
    "        cl_model.to(CONFIG.device)\n",
    "        model = PawpularModel(cl_model, model_name=CONFIG.MODEL_NAME)\n",
    "        model.to(CONFIG.device)\n",
    "\n",
    "        if torch.cuda.device_count()>1:\n",
    "            model=nn.DataParallel(model)\n",
    "            model.load_state_dict(torch.load(CONFIG.MODEL_PATH / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(fix_model_state_dict(torch.load(CONFIG.MODEL_PATH / f\"{CONFIG.MODEL_NAME}_{fold}_best.pth\")[\"model\"]))\n",
    "        #学習に向けたデータの準備\n",
    "        if CONFIG.training_step:\n",
    "            train_idx = train_df[train_df.fold!=fold].index\n",
    "            val_idx = train_df[train_df.fold ==fold].index\n",
    "            train_folds = train_df.loc[train_idx].reset_index(drop=True)\n",
    "            valid_folds = train_df.loc[val_idx].reset_index(drop=True)\n",
    "            test_folds = test_df.reset_index(drop=True)\n",
    "            preds_train, embed_train = extract_feature(model, train_folds)\n",
    "            preds_val, embed_val = extract_feature(model, valid_folds)\n",
    "            preds_test, embed_test = extract_feature(model, test_folds)\n",
    "\n",
    "            ##fit SVR to train data\n",
    "            print('Fitting SVR...')\n",
    "            clf = SVR(C =20.0)\n",
    "            clf.fit(embed_train.astype('float32'), train_folds.Pawpularity.values.astype('int32'))\n",
    "            pickle.dump(clf, open(CONFIG.OUTPUT_DIR / f\"SVR_fold_{fold}.pkl\", \"wb\"))\n",
    "        \n",
    "            ##fit SVR to oof data\n",
    "            oof_pred_SVR = clf.predict(embed_val.astype('float32'))\n",
    "            oof_pred_NN  =[sigmoid(x) * 100 for x in preds_val]\n",
    "            final_oof_true = valid_folds.Pawpularity.values.astype('int32')\n",
    "\n",
    "            super_final_oof_predictions.append(oof_pred_SVR)\n",
    "            super_final_oof_predictions2.append(oof_pred_NN)\n",
    "            super_final_oof_true.append(final_oof_true)\n",
    "\n",
    "            rsme_svr = np.sqrt(np.mean((np.array(final_oof_true) - np.array(oof_pred_SVR))**2.0))\n",
    "            print('SVR RSME =',rsme_svr,'\\n')\n",
    "\n",
    "            rsme_nn = np.sqrt(np.mean((np.array(final_oof_true) - np.array(oof_pred_NN))**2.0))\n",
    "            print('NN RSME =',rsme_nn,'\\n')\n",
    "\n",
    "            w = 0.5\n",
    "            oof2 = (1-w)*np.array(oof_pred_SVR) + w*np.array(oof_pred_NN)\n",
    "            rsme_en = np.sqrt( np.mean( (super_final_oof_true[-1] - oof2)**2.0 ) )\n",
    "            print('Ensemble RSME =',rsme_en,'\\n')\n",
    "        \n",
    "        else:\n",
    "            print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n",
    "            clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n",
    "        ##fit SVR to test data\n",
    "        test_pred_SVR = clf.predict(embed_test.astype('float32'))\n",
    "        test_pred_NN  =[sigmoid(x) * 100 for x in preds_test]\n",
    "        \n",
    "        super_final_predictions.append(test_pred_SVR)\n",
    "        super_final_predictions2.append(test_pred_NN)\n",
    "        \n",
    "    true = np.hstack(super_final_oof_true)\n",
    "\n",
    "    oof = np.hstack(super_final_oof_predictions)\n",
    "    rsme = np.sqrt( np.mean( (oof - true)**2.0 ))\n",
    "    print('Overall CV SVR head RSME =',rsme)\n",
    "\n",
    "    oof2 = np.hstack(super_final_oof_predictions2)\n",
    "    rsme = np.sqrt( np.mean( (oof2 - true)**2.0 ))\n",
    "    print('Overall CV NN head RSME =',rsme)\n",
    "\n",
    "    oof3 = (1-w)*oof + w*oof2\n",
    "    rsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\n",
    "    print('Overall CV Ensemble heads RSME with 50% NN and 50% SVR =',rsme)\n",
    "        \n",
    "    # submission\n",
    "    submission = test_df.copy()\n",
    "    \n",
    "    best_w = 0.8\n",
    "    super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n",
    "    super_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\n",
    "    submission[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\n",
    "    submission = submission[[\"Id\", \"Pawpularity\"]]\n",
    "    submission.to_csv(CONFIG.OUTPUT_DIR / \"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0a5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 extract ==========\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 793/793 [02:45<00:00,  4.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:42<00:00,  4.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 extract ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RSME = 17.82769543052886 \n",
      "\n",
      "NN RSME = 17.870076793513988 \n",
      "\n",
      "Ensemble RSME = 17.840261518578384 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 793/793 [02:50<00:00,  4.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:42<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "========== fold: 2 extract ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR...\n",
      "SVR RSME = 17.574549295704287 \n",
      "\n",
      "NN RSME = 17.585323578309445 \n",
      "\n",
      "Ensemble RSME = 17.314105945302313 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 793/793 [02:50<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:42<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 extract ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RSME = 17.620918713291093 \n",
      "\n",
      "NN RSME = 17.69470356080473 \n",
      "\n",
      "Ensemble RSME = 17.648792050282026 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 793/793 [02:49<00:00,  4.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:42<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 extract ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RSME = 18.026355352143273 \n",
      "\n",
      "NN RSME = 18.06876058518705 \n",
      "\n",
      "Ensemble RSME = 18.034970482864843 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 793/793 [02:48<00:00,  4.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 199/199 [00:42<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR...\n",
      "SVR RSME = 17.619606263128517 \n",
      "\n",
      "NN RSME = 17.727901894545735 \n",
      "\n",
      "Ensemble RSME = 17.658080149625054 \n",
      "\n",
      "Overall CV SVR head RSME = 17.734639062867057\n",
      "Overall CV NN head RSME = 17.790121876872355\n",
      "Overall CV Ensemble heads RSME with 50% NN and 50% SVR = 17.700828679671\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e96fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb62c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffab959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf8e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
